{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from devtools import pprint \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from helper import one_hot_encoding\n",
    "from tqdm import tqdm\n",
    "random_state = 42\n",
    "random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions \n",
    "A couple of function used to: \n",
    "- `train_validation_test_split`: split the dataset into train,validation and test\n",
    "- `get_time_matrix`: get the time values of each combination in a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(x, y, weights = [], test_buckets = []):\n",
    "    BUCKETS = 10\n",
    "\n",
    "    N_ELEMENTS = len(x)\n",
    "\n",
    "    BUCKET_SIZE = N_ELEMENTS // BUCKETS\n",
    "\n",
    "    TEST_BUCKETS = 1\n",
    "\n",
    "\n",
    "    x_local = x.copy()\n",
    "    y_local = y.copy()\n",
    "    weights = [w for w in weights] if len(weights) == len(y) else [1 for _ in range(len(y))]\n",
    "    x_test, y_test = [], []\n",
    "    #If the test bucket(s) has not been provided, generate it randomly\n",
    "    if len(test_buckets) == 0: \n",
    "        for _ in range(TEST_BUCKETS):\n",
    "            idx = random.randint(0, BUCKETS - 1)\n",
    "            while idx in test_buckets:\n",
    "                idx = random.randint(0, BUCKETS - 1)\n",
    "            test_buckets.append(idx)\n",
    "\n",
    "    #Generate the test set\n",
    "    for bucket in test_buckets:\n",
    "        idx = bucket * BUCKET_SIZE\n",
    "        for _ in range(BUCKET_SIZE):\n",
    "            weights.pop(idx)\n",
    "            x_test.append(x_local.pop(idx))\n",
    "            y_test.append(y_local.pop(idx))\n",
    "\n",
    "    #generate the train set as 90% of the remaining dataset\n",
    "    train_elements = (len(y_local) // 10) * 9\n",
    "    x_train = x_local[:train_elements]\n",
    "    y_train = y_local[:train_elements]\n",
    "    train_weights = weights[:train_elements]\n",
    "\n",
    "    #generate the valdation set as 10% of the validation data\n",
    "    x_validation = x_local[train_elements:]\n",
    "    y_validation = y_local[train_elements:]\n",
    "    \n",
    "    return (x_train, y_train, train_weights), (x_validation, y_validation), (x_test, y_test)\n",
    "\n",
    "def get_time_matrix(shape:tuple, times:list[list[dict]]):\n",
    "    time_matrix = np.zeros(shape)\n",
    "    for i in range(len(times)):\n",
    "        times_i = times[i]\n",
    "        for j in range(len(times_i)):\n",
    "            time_matrix[i,j] = times_i[j][\"time\"]\n",
    "    return time_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = \"../features\"\n",
    "files = [f for f in os.listdir(features_dir) if os.path.isfile(os.path.join(features_dir, f))]\n",
    "data = {}\n",
    "#load all the features in memory\n",
    "for file in files:\n",
    "    with open(features_dir + \"/\" + file) as f:\n",
    "        data[file] = json.load(f)\n",
    "splitted = [file.replace(\".json\", \"\").replace(\".param\", \"\").split(\"_\") for file in files]\n",
    "models = np.unique([\"_\".join(split[:-1]) for split in splitted]).tolist()\n",
    "instances = np.unique([split[-1] for split in splitted]).tolist()\n",
    "models = [\"01_compact.eprime\"]\n",
    "instances_data = {}\n",
    "#save the features as model that generates them - instance\n",
    "for instance in instances:\n",
    "    for model in models:\n",
    "        instances_data[instance] = data[f\"{model}_{instance}.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the dataset\n",
    "f = open(\"../data/datasets/dataset_CarSequencing-2024-03-19.json\")\n",
    "dataset = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datapoint in dataset:\n",
    "    instance = datapoint[\"instance_name\"].split(\"/\")[-1].replace(\".param\", \".fnz2feat\")\n",
    "    datapoint[\"features\"] = instances_data[instance]\n",
    "    datapoint[\"all_times\"] = sorted(datapoint[\"all_times\"], key= lambda x: x[\"combination\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combination</th>\n",
       "      <th>time</th>\n",
       "      <th>instance_value</th>\n",
       "      <th>instance_name</th>\n",
       "      <th>all_times</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cplex_06_chPrunedLevels.eprime</td>\n",
       "      <td>3.18</td>\n",
       "      <td>language Essence 1.3\\n\\nletting blksize_delta ...</td>\n",
       "      <td>params/generated/c28b092a8f728601da45adef533a2...</td>\n",
       "      <td>[{'time': 41.64, 'combination': 'chuffed_01_co...</td>\n",
       "      <td>{'c_avg_deg_cons': 8.55327, 'c_avg_dom_cons': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>or-tools-1_06_chPrunedLevels.eprime</td>\n",
       "      <td>1.85</td>\n",
       "      <td>language Essence 1.3\\n\\nletting blksize_delta ...</td>\n",
       "      <td>params/generated/bda2c9118004a4f49b43c1d56d23b...</td>\n",
       "      <td>[{'time': 64.38, 'combination': 'chuffed_01_co...</td>\n",
       "      <td>{'c_avg_deg_cons': 5.84957, 'c_avg_dom_cons': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chuffed_01_compact.eprime</td>\n",
       "      <td>12.48</td>\n",
       "      <td>language Essence 1.3\\n\\nletting blksize_delta ...</td>\n",
       "      <td>params/generated/33ee22ee78354fcd6547ae283d854...</td>\n",
       "      <td>[{'time': 12.48, 'combination': 'chuffed_01_co...</td>\n",
       "      <td>{'c_avg_deg_cons': 4.71617, 'c_avg_dom_cons': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>or-tools-1_01_compact.eprime</td>\n",
       "      <td>1.57</td>\n",
       "      <td>language Essence 1.3\\n\\nletting blksize_delta ...</td>\n",
       "      <td>params/generated/6549d86c3e82a1cc9ad6d047b8b70...</td>\n",
       "      <td>[{'time': 64.16, 'combination': 'chuffed_01_co...</td>\n",
       "      <td>{'c_avg_deg_cons': 5.35605, 'c_avg_dom_cons': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chuffed_01_compact.eprime</td>\n",
       "      <td>12.94</td>\n",
       "      <td>language Essence 1.3\\n\\nletting blksize_delta ...</td>\n",
       "      <td>params/generated/7b01e73519f42cb521ac7f638a98a...</td>\n",
       "      <td>[{'time': 12.94, 'combination': 'chuffed_01_co...</td>\n",
       "      <td>{'c_avg_deg_cons': 3.91856, 'c_avg_dom_cons': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           combination   time  \\\n",
       "0       cplex_06_chPrunedLevels.eprime   3.18   \n",
       "1  or-tools-1_06_chPrunedLevels.eprime   1.85   \n",
       "2            chuffed_01_compact.eprime  12.48   \n",
       "3         or-tools-1_01_compact.eprime   1.57   \n",
       "4            chuffed_01_compact.eprime  12.94   \n",
       "\n",
       "                                      instance_value  \\\n",
       "0  language Essence 1.3\\n\\nletting blksize_delta ...   \n",
       "1  language Essence 1.3\\n\\nletting blksize_delta ...   \n",
       "2  language Essence 1.3\\n\\nletting blksize_delta ...   \n",
       "3  language Essence 1.3\\n\\nletting blksize_delta ...   \n",
       "4  language Essence 1.3\\n\\nletting blksize_delta ...   \n",
       "\n",
       "                                       instance_name  \\\n",
       "0  params/generated/c28b092a8f728601da45adef533a2...   \n",
       "1  params/generated/bda2c9118004a4f49b43c1d56d23b...   \n",
       "2  params/generated/33ee22ee78354fcd6547ae283d854...   \n",
       "3  params/generated/6549d86c3e82a1cc9ad6d047b8b70...   \n",
       "4  params/generated/7b01e73519f42cb521ac7f638a98a...   \n",
       "\n",
       "                                           all_times  \\\n",
       "0  [{'time': 41.64, 'combination': 'chuffed_01_co...   \n",
       "1  [{'time': 64.38, 'combination': 'chuffed_01_co...   \n",
       "2  [{'time': 12.48, 'combination': 'chuffed_01_co...   \n",
       "3  [{'time': 64.16, 'combination': 'chuffed_01_co...   \n",
       "4  [{'time': 12.94, 'combination': 'chuffed_01_co...   \n",
       "\n",
       "                                            features  \n",
       "0  {'c_avg_deg_cons': 8.55327, 'c_avg_dom_cons': ...  \n",
       "1  {'c_avg_deg_cons': 5.84957, 'c_avg_dom_cons': ...  \n",
       "2  {'c_avg_deg_cons': 4.71617, 'c_avg_dom_cons': ...  \n",
       "3  {'c_avg_deg_cons': 5.35605, 'c_avg_dom_cons': ...  \n",
       "4  {'c_avg_deg_cons': 3.91856, 'c_avg_dom_cons': ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dataset)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = []\n",
    "times = []\n",
    "for i in range(len(data)):\n",
    "    row = data.iloc[i,:]\n",
    "    current_feat = {\"inst\": row[\"instance_name\"]}\n",
    "    current_feat.update(row[\"features\"])\n",
    "    feat.append(current_feat)\n",
    "    current_times = {\"inst\": row[\"instance_name\"]}\n",
    "    for time in row[\"all_times\"]:\n",
    "        current_times[time[\"combination\"]] = time[\"time\"]\n",
    "    times.append(current_times)\n",
    "\n",
    "features = pd.DataFrame(feat)\n",
    "features.set_index('inst', inplace=True)\n",
    "times = pd.DataFrame(times)\n",
    "times.set_index('inst', inplace=True)\n",
    "features.to_csv(\"../data/datasets/dataset_CarSequencing_features-2024-03-19.csv\")\n",
    "times.to_csv(\"../data/datasets/dataset_CarSequencing_times-2024-03-19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"features\"]\n",
    "X = [x for x in X.values]\n",
    "weights = [sum([1 if t[\"time\"] > 3600 else 0 for t in times]) for times in data[\"all_times\"].to_list()]\n",
    "y = [datapoint for datapoint in data[\"combination\"].to_list()]\n",
    "combinations = [d[\"combination\"] for d in data[\"all_times\"].tolist()[0]]\n",
    "y = one_hot_encoding(y, combinations)\n",
    "y  = [y_t.numpy() for y_t in y]\n",
    "\n",
    "all_times = [datapoint[\"all_times\"] for datapoint in dataset]\n",
    "times_matrix = get_time_matrix((len(all_times), len(combinations)), all_times)\n",
    "y_np = np.array(y)\n",
    "majority_index = np.argmax([np.sum(y_np[:, i]) for i in range(len(combinations))])\n",
    "\n",
    "bucket_size = len(X) // 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a randomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training on different dataset splits: 100%|██████████| 10/10 [16:55:16<00:00, 6091.65s/it] \n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "#repeat the experiment for different train/validation/test splits\n",
    "for test_bucket in tqdm(range(10), \"training on different dataset splits\"):\n",
    "    (X_train, y_train, _), (X_validation, y_validation), (X_test, y_test) = train_validation_test_split(X,y, weights=weights, test_buckets=[test_bucket])\n",
    "    X_train, X_validation, X_test = pd.DataFrame(X_train), pd.DataFrame(X_validation), pd.DataFrame(X_test)\n",
    "\n",
    "    test_start = test_bucket * bucket_size\n",
    "    test_idxs = [test_start + k for k in range(len(y_test))]\n",
    "    train_val_idxs = [k for k in range(len(y)) if not k in test_idxs]\n",
    "    train_elements = (len(train_val_idxs) // 10) * 9\n",
    "    train_idxs = train_val_idxs[:train_elements]\n",
    "    validation_idxs = train_val_idxs[train_elements:]\n",
    "\n",
    "    assert len(test_idxs) == len(y_test)\n",
    "    assert len(validation_idxs) == len(y_validation)\n",
    "    assert len(train_idxs) == len(y_train)\n",
    "\n",
    "    #Virtual best\n",
    "    min_train = sum([min(times_matrix[i, :]) for i in train_idxs])\n",
    "    min_val = sum([min(times_matrix[i, :]) for i in validation_idxs])\n",
    "    min_test = sum([min(times_matrix[i, :]) for i in test_idxs])\n",
    "\n",
    "    #majority classifier: AKA single best with highest wins\n",
    "    majority_train = sum([times_matrix[i, majority_index] for i in train_idxs])\n",
    "    majority_val = sum([times_matrix[i, majority_index] for i in validation_idxs])\n",
    "    majority_test = sum([times_matrix[i, majority_index] for i in test_idxs])\n",
    "\n",
    "    #single best with lowest time\n",
    "    sb_t = [sum([times_matrix[i, j] for i in train_idxs]) for j in range(len(combinations))]\n",
    "    sb_v = [sum([times_matrix[i, j] for i in validation_idxs]) for j in range(len(combinations))]\n",
    "    sb_te = [sum([times_matrix[i,j] for i in test_idxs]) for j in range(len(combinations))]\n",
    "\n",
    "    sb_train = min(sb_t)\n",
    "    sb_validation = min(sb_v)\n",
    "    sb_test = min(sb_te)\n",
    "\n",
    "\n",
    "    #generating a list of hyperprameters to find the best randomForest \n",
    "    paramters_range = [\n",
    "        {\"criterion\":[\"gini\", \"entropy\", \"log_loss\"], \n",
    "         \"max_depth\":[10,20,30, 40], \n",
    "         \"min_samples_split\": [2, 4, 8, 16], \n",
    "         \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "         \"bootstrap\": [True, False]}]\n",
    "    parameters = list(ParameterGrid(paramters_range))\n",
    "    val_scores = []\n",
    "    train_scores = []\n",
    "    e = lambda x: np.argmax(x)\n",
    "    #training a randomForest for each hyperparameter set\n",
    "    for i in range(len(parameters)):\n",
    "        param = parameters[i]\n",
    "        forest = RandomForestClassifier(**param,random_state=random_state)\n",
    "        forest.fit(X_train, y_train)\n",
    "        y_pred_val = forest.predict(X_validation)\n",
    "        y_pred_train = forest.predict(X_train)\n",
    "        val_score = sum([times_matrix[idx, e(y_pred_val[i])] for idx in validation_idxs])\n",
    "        train_score = sum([times_matrix[idx, e(y_pred_train[i])] for idx in train_idxs])\n",
    "        val_scores.append(np.mean(val_score))\n",
    "        train_scores.append(np.mean(train_score))\n",
    "\n",
    "    #taking the model with lowest validation time\n",
    "    best_tree_val = RandomForestClassifier(**parameters[np.argmin(val_scores)], random_state=random_state)\n",
    "    best_tree_val.fit(X_train, y_train)\n",
    "    y_test_predicted = best_tree_val.predict(X_test)\n",
    "    y_train_predicted = best_tree_val.predict(X_train)\n",
    "    y_val_predicted = best_tree_val.predict(X_validation)\n",
    "\n",
    "    #ŧesting on the different datasets\n",
    "    times_train = [times_matrix[train_idxs[i], e(y_train_predicted[i])] for i in range(len(y_train))]\n",
    "    times_validation = [times_matrix[train_idxs[i], e(y_val_predicted[i])] for i in range(len(y_validation))]\n",
    "    times_test = [times_matrix[train_idxs[i], e(y_test_predicted[i])] for i in range(len(y_test))]\n",
    "    \n",
    "    #saving the outcome\n",
    "    stats.append({\n",
    "        \"train_time\": round(sum(times_train), 2),\n",
    "        \"vb_train\": round(min_train, 2),\n",
    "        \"sb_min_time_train\": round(sb_train, 2),\n",
    "        \"sb_max_wins_train\":round(majority_train, 2),\n",
    "        \"validation_time\": round(sum(times_validation), 2),\n",
    "        \"vb_val\": round(min_val, 2),\n",
    "        \"sb_min_time_val\": round(sb_validation, 2),\n",
    "        \"sb_max_wins_val\":round(majority_val, 2),\n",
    "        \"test_time\": round(sum(times_test), 2),\n",
    "        \"vb_test\": round(min_test, 2),\n",
    "        \"sb_min_time_test\": round(sb_test, 2),\n",
    "        \"sb_max_wins_test\": round(majority_test, 2),\n",
    "        \"train_accuracy\": round(accuracy_score(y_train, y_train_predicted) * 100, 2),\n",
    "        \"validation_accuracy\": round(accuracy_score(y_validation, y_val_predicted) * 100, 2),\n",
    "        \"test_accuracy\": round(accuracy_score(y_test, y_test_predicted) * 100, 2),\n",
    "        \"best_val_params\": parameters[np.argmin(val_scores)],\n",
    "        \"best_train_params\": parameters[np.argmin(train_scores)]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>vb_train</th>\n",
       "      <th>sb_min_time_train</th>\n",
       "      <th>sb_max_wins_train</th>\n",
       "      <th>validation_time</th>\n",
       "      <th>vb_val</th>\n",
       "      <th>sb_min_time_val</th>\n",
       "      <th>sb_max_wins_val</th>\n",
       "      <th>test_time</th>\n",
       "      <th>vb_test</th>\n",
       "      <th>sb_min_time_test</th>\n",
       "      <th>sb_max_wins_test</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_val_params</th>\n",
       "      <th>best_train_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1289237.24</td>\n",
       "      <td>87870.97</td>\n",
       "      <td>5884935.90</td>\n",
       "      <td>8065799.59</td>\n",
       "      <td>1534489.40</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1179451.12</td>\n",
       "      <td>11133.69</td>\n",
       "      <td>872317.00</td>\n",
       "      <td>1318486.28</td>\n",
       "      <td>72.45</td>\n",
       "      <td>23.21</td>\n",
       "      <td>22.04</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1686435.71</td>\n",
       "      <td>88037.02</td>\n",
       "      <td>5945863.14</td>\n",
       "      <td>8350954.45</td>\n",
       "      <td>1711143.97</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1551857.26</td>\n",
       "      <td>10967.64</td>\n",
       "      <td>719066.84</td>\n",
       "      <td>1033331.42</td>\n",
       "      <td>71.06</td>\n",
       "      <td>22.99</td>\n",
       "      <td>20.76</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656524.17</td>\n",
       "      <td>88302.17</td>\n",
       "      <td>5956449.56</td>\n",
       "      <td>8302512.98</td>\n",
       "      <td>1607786.56</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1644413.96</td>\n",
       "      <td>10702.49</td>\n",
       "      <td>800803.34</td>\n",
       "      <td>1081772.89</td>\n",
       "      <td>71.02</td>\n",
       "      <td>23.32</td>\n",
       "      <td>21.35</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'log_loss', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1477086.97</td>\n",
       "      <td>87887.30</td>\n",
       "      <td>6036658.51</td>\n",
       "      <td>8460139.78</td>\n",
       "      <td>1536784.53</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1792708.93</td>\n",
       "      <td>11117.36</td>\n",
       "      <td>720594.39</td>\n",
       "      <td>924146.09</td>\n",
       "      <td>72.53</td>\n",
       "      <td>23.43</td>\n",
       "      <td>24.19</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465896.24</td>\n",
       "      <td>87948.35</td>\n",
       "      <td>5926275.11</td>\n",
       "      <td>8205605.44</td>\n",
       "      <td>1428338.07</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1563398.72</td>\n",
       "      <td>11056.31</td>\n",
       "      <td>738913.26</td>\n",
       "      <td>1178680.43</td>\n",
       "      <td>73.51</td>\n",
       "      <td>23.21</td>\n",
       "      <td>21.35</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1615021.94</td>\n",
       "      <td>88079.73</td>\n",
       "      <td>6102529.35</td>\n",
       "      <td>8208551.00</td>\n",
       "      <td>1738137.45</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1359729.08</td>\n",
       "      <td>10924.93</td>\n",
       "      <td>654723.55</td>\n",
       "      <td>1175734.87</td>\n",
       "      <td>72.77</td>\n",
       "      <td>21.48</td>\n",
       "      <td>22.04</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1534642.37</td>\n",
       "      <td>88107.62</td>\n",
       "      <td>6034561.82</td>\n",
       "      <td>8534636.19</td>\n",
       "      <td>1446471.97</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1579382.85</td>\n",
       "      <td>10897.04</td>\n",
       "      <td>722691.08</td>\n",
       "      <td>849649.68</td>\n",
       "      <td>71.24</td>\n",
       "      <td>21.26</td>\n",
       "      <td>21.45</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1219820.16</td>\n",
       "      <td>88196.11</td>\n",
       "      <td>6035095.80</td>\n",
       "      <td>8496185.01</td>\n",
       "      <td>1476378.03</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1307998.81</td>\n",
       "      <td>10808.55</td>\n",
       "      <td>722157.10</td>\n",
       "      <td>888100.86</td>\n",
       "      <td>72.55</td>\n",
       "      <td>23.43</td>\n",
       "      <td>22.53</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1724616.79</td>\n",
       "      <td>88665.98</td>\n",
       "      <td>6140539.05</td>\n",
       "      <td>8527943.28</td>\n",
       "      <td>1481868.67</td>\n",
       "      <td>9948.37</td>\n",
       "      <td>532968.02</td>\n",
       "      <td>883958.00</td>\n",
       "      <td>1803897.14</td>\n",
       "      <td>10338.68</td>\n",
       "      <td>616713.85</td>\n",
       "      <td>856342.59</td>\n",
       "      <td>70.67</td>\n",
       "      <td>21.37</td>\n",
       "      <td>22.62</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4435197.09</td>\n",
       "      <td>88758.17</td>\n",
       "      <td>6213070.61</td>\n",
       "      <td>8495033.36</td>\n",
       "      <td>1339489.70</td>\n",
       "      <td>9214.72</td>\n",
       "      <td>539347.13</td>\n",
       "      <td>811478.74</td>\n",
       "      <td>1260435.78</td>\n",
       "      <td>10980.14</td>\n",
       "      <td>600849.68</td>\n",
       "      <td>961731.77</td>\n",
       "      <td>22.22</td>\n",
       "      <td>9.98</td>\n",
       "      <td>9.40</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_time  vb_train  sb_min_time_train  sb_max_wins_train  \\\n",
       "0  1289237.24  87870.97         5884935.90         8065799.59   \n",
       "1  1686435.71  88037.02         5945863.14         8350954.45   \n",
       "2  1656524.17  88302.17         5956449.56         8302512.98   \n",
       "3  1477086.97  87887.30         6036658.51         8460139.78   \n",
       "4  1465896.24  87948.35         5926275.11         8205605.44   \n",
       "5  1615021.94  88079.73         6102529.35         8208551.00   \n",
       "6  1534642.37  88107.62         6034561.82         8534636.19   \n",
       "7  1219820.16  88196.11         6035095.80         8496185.01   \n",
       "8  1724616.79  88665.98         6140539.05         8527943.28   \n",
       "9  4435197.09  88758.17         6213070.61         8495033.36   \n",
       "\n",
       "   validation_time   vb_val  sb_min_time_val  sb_max_wins_val   test_time  \\\n",
       "0       1534489.40  9948.37        532968.02        883958.00  1179451.12   \n",
       "1       1711143.97  9948.37        532968.02        883958.00  1551857.26   \n",
       "2       1607786.56  9948.37        532968.02        883958.00  1644413.96   \n",
       "3       1536784.53  9948.37        532968.02        883958.00  1792708.93   \n",
       "4       1428338.07  9948.37        532968.02        883958.00  1563398.72   \n",
       "5       1738137.45  9948.37        532968.02        883958.00  1359729.08   \n",
       "6       1446471.97  9948.37        532968.02        883958.00  1579382.85   \n",
       "7       1476378.03  9948.37        532968.02        883958.00  1307998.81   \n",
       "8       1481868.67  9948.37        532968.02        883958.00  1803897.14   \n",
       "9       1339489.70  9214.72        539347.13        811478.74  1260435.78   \n",
       "\n",
       "    vb_test  sb_min_time_test  sb_max_wins_test  train_accuracy  \\\n",
       "0  11133.69         872317.00        1318486.28           72.45   \n",
       "1  10967.64         719066.84        1033331.42           71.06   \n",
       "2  10702.49         800803.34        1081772.89           71.02   \n",
       "3  11117.36         720594.39         924146.09           72.53   \n",
       "4  11056.31         738913.26        1178680.43           73.51   \n",
       "5  10924.93         654723.55        1175734.87           72.77   \n",
       "6  10897.04         722691.08         849649.68           71.24   \n",
       "7  10808.55         722157.10         888100.86           72.55   \n",
       "8  10338.68         616713.85         856342.59           70.67   \n",
       "9  10980.14         600849.68         961731.77           22.22   \n",
       "\n",
       "   validation_accuracy  test_accuracy  \\\n",
       "0                23.21          22.04   \n",
       "1                22.99          20.76   \n",
       "2                23.32          21.35   \n",
       "3                23.43          24.19   \n",
       "4                23.21          21.35   \n",
       "5                21.48          22.04   \n",
       "6                21.26          21.45   \n",
       "7                23.43          22.53   \n",
       "8                21.37          22.62   \n",
       "9                 9.98           9.40   \n",
       "\n",
       "                                     best_val_params  \\\n",
       "0  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "1  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "2  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "3  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "4  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "5  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "6  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "7  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "8  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "9  {'bootstrap': True, 'criterion': 'gini', 'max_...   \n",
       "\n",
       "                                   best_train_params  \n",
       "0  {'bootstrap': True, 'criterion': 'gini', 'max_...  \n",
       "1  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "2  {'bootstrap': True, 'criterion': 'log_loss', '...  \n",
       "3  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "4  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "5  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "6  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "7  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "8  {'bootstrap': False, 'criterion': 'entropy', '...  \n",
       "9  {'bootstrap': False, 'criterion': 'entropy', '...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest for fold 0 minimising validation time has stats:\n",
      "    train time / single best min time: 0.2190741346902351\n",
      "    train time / single best max wins: 0.1598399793615502\n",
      "    validation time / single best min time: 2.8791397277457658\n",
      "    validation time / single best max wins: 1.7359302138789399\n",
      "    test time / single best min time: 1.3520900314908457\n",
      "    test time / single best max wins: 0.8945494070670194\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 1 minimising validation time has stats:\n",
      "    train time / single best min time: 0.28363177393955286\n",
      "    train time / single best max wins: 0.20194526507086863\n",
      "    validation time / single best min time: 3.2105940802977257\n",
      "    validation time / single best max wins: 1.935775195201582\n",
      "    test time / single best min time: 2.158154393547059\n",
      "    test time / single best max wins: 1.501800129139594\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 2 minimising validation time has stats:\n",
      "    train time / single best min time: 0.2781059678779518\n",
      "    train time / single best max wins: 0.19952081664797347\n",
      "    validation time / single best min time: 3.016666103155683\n",
      "    validation time / single best max wins: 1.8188494928492078\n",
      "    test time / single best min time: 2.0534554214022136\n",
      "    test time / single best max wins: 1.5201101591665882\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 3 minimising validation time has stats:\n",
      "    train time / single best min time: 0.24468618981066068\n",
      "    train time / single best max wins: 0.17459368384100152\n",
      "    validation time / single best min time: 2.8834460461623945\n",
      "    validation time / single best max wins: 1.7385266381434412\n",
      "    test time / single best min time: 2.487819715054956\n",
      "    test time / single best max wins: 1.9398544769041872\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 4 minimising validation time has stats:\n",
      "    train time / single best min time: 0.24735541512854267\n",
      "    train time / single best max wins: 0.17864571367935525\n",
      "    validation time / single best min time: 2.6799695598996727\n",
      "    validation time / single best max wins: 1.6158438183714612\n",
      "    test time / single best min time: 2.115808180245676\n",
      "    test time / single best max wins: 1.3263974527854\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 5 minimising validation time has stats:\n",
      "    train time / single best min time: 0.26464795945635233\n",
      "    train time / single best max wins: 0.19674872459219658\n",
      "    validation time / single best min time: 3.261241546913077\n",
      "    validation time / single best max wins: 1.9663122569171838\n",
      "    test time / single best min time: 2.0767987954610767\n",
      "    test time / single best max wins: 1.156492943005084\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 6 minimising validation time has stats:\n",
      "    train time / single best min time: 0.25430883231883106\n",
      "    train time / single best max wins: 0.17981344908387947\n",
      "    validation time / single best min time: 2.7139939278157814\n",
      "    validation time / single best max wins: 1.6363582545777062\n",
      "    test time / single best min time: 2.1854190451610394\n",
      "    test time / single best max wins: 1.8588635848129784\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 7 minimising validation time has stats:\n",
      "    train time / single best min time: 0.20212109309018755\n",
      "    train time / single best max wins: 0.14357269275142584\n",
      "    validation time / single best min time: 2.770106225135234\n",
      "    validation time / single best max wins: 1.6701902465954266\n",
      "    test time / single best min time: 1.8112385933753197\n",
      "    test time / single best max wins: 1.4728043501725694\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 8 minimising validation time has stats:\n",
      "    train time / single best min time: 0.28085755598280904\n",
      "    train time / single best max wins: 0.20223126882710696\n",
      "    validation time / single best min time: 2.780408231623353\n",
      "    validation time / single best max wins: 1.6764016729301618\n",
      "    test time / single best min time: 2.9250148022458067\n",
      "    test time / single best max wins: 2.106513399035776\n",
      "\n",
      "====================================================================================================\n",
      "The best random forest for fold 9 minimising validation time has stats:\n",
      "    train time / single best min time: 0.7138494584081347\n",
      "    train time / single best max wins: 0.5220929573842191\n",
      "    validation time / single best min time: 2.483539126276615\n",
      "    validation time / single best max wins: 1.650677502653982\n",
      "    test time / single best min time: 2.097755598371959\n",
      "    test time / single best max wins: 1.3105897291923714\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx, tree_stats in enumerate(stats):\n",
    "    print(f\"\"\"The best random forest for fold {idx} minimising validation time has stats:\n",
    "    train time / single best min time: {tree_stats[\"train_time\"] / tree_stats[\"sb_min_time_train\"]}\n",
    "    train time / single best max wins: {tree_stats[\"train_time\"] / tree_stats[\"sb_max_wins_train\"]}\n",
    "    validation time / single best min time: {tree_stats[\"validation_time\"] / tree_stats[\"sb_min_time_val\"]}\n",
    "    validation time / single best max wins: {tree_stats[\"validation_time\"] / tree_stats[\"sb_max_wins_val\"]}\n",
    "    test time / single best min time: {tree_stats[\"test_time\"] / tree_stats[\"sb_min_time_test\"]}\n",
    "    test time / single best max wins: {tree_stats[\"test_time\"] / tree_stats[\"sb_max_wins_test\"]}\n",
    "\"\"\")\n",
    "    print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
